{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext(\"local[*]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.textFile(\"Posts.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "rdd_text = rdd.map(lambda x: [get_field(x, \"Body\")])#re.search(\"Body=\\\"(.*?)\\\"\", x))\n",
    "rdd_text = rdd_text.filter(lambda x: x is not None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['team-fortress-2'],\n",
       " ['starcraft-2', 'starcraft-protoss'],\n",
       " ['steam', 'source-engine'],\n",
       " ['the-secret-of-monkey-island'],\n",
       " ['backwards-compatibility', 'windows-xp', 'sam-and-max']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_tags = rdd.map(lambda x: re.search(\"Tags=\\\"(.*?)\\\"\", x))\n",
    "rdd_tags = rdd_tags.filter(lambda x: x is not None).map(lambda x: x.group(1))\n",
    "rdd_tags = rdd_tags.map(lambda x: remove_tag_brackets(x))\n",
    "rdd_tags.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tag_brackets(text):\n",
    "    text = text.replace(\"&gt;&lt;\", \" \")\n",
    "    text = text.replace(\"&gt;\", \"\")\n",
    "    text = text.replace(\"&lt;\", \"\")\n",
    "    text = text.split()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `replace` not found.\n"
     ]
    }
   ],
   "source": [
    "\"\".replace?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\".replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['&lt;p&gt;Now that the Engineer update has come, there will be lots of Engineers building up everywhere.  How should this best be handled?&lt;/p&gt;&#xA;',\n",
       " \"&lt;p&gt;I know I can create a Warp Gate and teleport to Pylons, but I have no idea how to make Warp Prisms or know if there's any other unit capable of transporting.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I would in particular like this to built remote bases in 1v1&lt;/p&gt;&#xA;\",\n",
       " \"&lt;p&gt;Steam won't let me have two instances running with the same user logged in.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Does that mean I cannot run a dedicated server on a PC (for example, for Left 4 Dead 2) &lt;em&gt;and&lt;/em&gt; play from another machine?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is there a way to run the dedicated server without running Steam? Is there a configuration option I'm missing?&lt;/p&gt;&#xA;\",\n",
       " '&lt;p&gt;When I get to the insult sword-fighting stage of The Secret of Monkey Island, do I have to learn every single insult and comeback in order to beat the Sword Master?&lt;/p&gt;&#xA;',\n",
       " \"&lt;p&gt;The kids picked up a copy of Sam &amp;amp; Max Hit the Road, but I can't get it to install. What do I have to do?&lt;/p&gt;&#xA;\"]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_text.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_field(line, field_name):\n",
    "    found = re.search(\"{}=\\\"(.*?)\\\"\".format(field_name), line)\n",
    "    if found:\n",
    "        return found.group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARBITRATRY_CUTOFF_VALUE = 2\n",
    "\n",
    "def get_relevant_fields(line):\n",
    "    return [get_field(line, \"Body\"),\n",
    "            #get_field(line, \"Tags\"),\n",
    "            get_field(line, \"Score\")]\n",
    "\n",
    "\n",
    "def any_missing(row):\n",
    "    return row[0] and row[1]# and row[2]\n",
    "\n",
    "\n",
    "def preprocess_scores(score):\n",
    "    score = int(score)\n",
    "    return 1 if score > 0 else 0\n",
    "\n",
    "\n",
    "def preprocess_tags(tags):\n",
    "    tags = tags.replace(\"&gt;&lt;\", \" \")\n",
    "    tags = tags.replace(\"&gt;\", \"\")\n",
    "    tags = tags.replace(\"&lt;\", \"\")\n",
    "    tags = tags.split()\n",
    "    return len(tags)\n",
    "\n",
    "\n",
    "def remove_stop_words(counter):\n",
    "    stop_words = set([\"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"arent\", \n",
    "                     \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \n",
    "                     \"cant\", \"cannot\", \"could\", \"couldnt\", \"did\", \"didnt\", \"do\", \"does\", \"doesnt\", \"doing\", \"dont\", \"down\", \n",
    "                     \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"hadnt\", \"has\", \"hasnt\", \"have\", \"havent\", \n",
    "                     \"having\", \"he\", \"hed\", \"hell\", \"hes\", \"her\", \"here\", \"heres\", \"hers\", \"herself\", \"him\", \"himself\", \n",
    "                     \"his\", \"how\", \"hows\", \"i\", \"id\", \"ill\", \"im\", \"ive\", \"if\", \"in\", \"into\", \"is\", \"isnt\", \"it\", \"its\", \n",
    "                     \"its\", \"itself\", \"lets\", \"me\", \"more\", \"most\", \"mustnt\", \"my\", \"myself\", \"no\", \"nor\", \"not\", \"of\", \n",
    "                     \"off\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours \tourselves\", \"out\", \"over\", \"own\", \n",
    "                     \"same\", \"shant\", \"she\", \"shed\", \"shell\", \"shes\", \"should\", \"shouldnt\", \"so\", \"some\", \"such\", \"than\", \n",
    "                     \"that\", \"thats\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"theres\", \"these\", \n",
    "                     \"they\", \"theyd\", \"theyll\", \"theyre\", \"theyve\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \n",
    "                     \"until\", \"up\", \"very\", \"was\", \"wasnt\", \"we\", \"wed\", \"well\", \"were\", \"weve\", \"were\", \"werent\", \"what\", \n",
    "                     \"whats\", \"when\", \"whens\", \"where\", \"wheres\", \"which\", \"while\", \"who\", \"whos\", \"whom\", \"why\", \"whys\", \n",
    "                     \"with\", \"wont\", \"would\", \"wouldnt\", \"you\", \"youd\", \"youll\", \"youre\", \"youve\", \"your\", \"yours\", \n",
    "                     \"yourself\", \"yourselves\"])\n",
    "    words = set(counter.keys())\n",
    "    for word in words:\n",
    "        if word in stop_words:\n",
    "            del counter[word]\n",
    "    return counter\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # remove code snippets\n",
    "    text = re.sub(\"&lt;pre&gt;&lt;code&gt;.*?&lt;/pre&gt;&lt;/code&gt;\", \"\", text)\n",
    "    \n",
    "    # remove html tags\n",
    "    text = re.sub(\"&lt;.*?&gt;\", \"\", text)\n",
    "    \n",
    "    #remove whatever this is\n",
    "    text = re.sub(\"&#xA;\", \"\", text)\n",
    "    \n",
    "    # remove links\n",
    "    text = re.sub(\"https?://.*?\\s|$\", \"\", text)\n",
    "    \n",
    "    # remove symbols\n",
    "    text = re.sub(\"[^a-zA-Z\\s]\", \"\", text)\n",
    "    \n",
    "    # normalize whitespace\n",
    "    text = re.sub(\"\\s+\", \" \", text)\n",
    "    \n",
    "    # lowercase everything\n",
    "    text = text.lower()\n",
    "    \n",
    "    # split text into words\n",
    "    split = text.split()\n",
    "\n",
    "    # count words\n",
    "    counter = Counter(split)\n",
    "    \n",
    "    # remove stop words\n",
    "    counter = remove_stop_words(counter)\n",
    "    \n",
    "    return counter\n",
    "\n",
    "def preprocess_all(row):\n",
    "    return (preprocess_text(row[0]), preprocess_scores(row[1]), 1)\n",
    "\n",
    "\n",
    "assert preprocess_text(\"&lt;pre&gt;&lt;code&gt;cprintf('hello world!');&lt;/pre&gt;&lt;/code&gt;\"\n",
    "                       \"https://google.com \"\n",
    "                       \"boulder leave it's it it?&lt;pre&gt;&lt;/pre&gt;\") == Counter([\"leave\", \"boulder\"])\n",
    "\n",
    "\n",
    "def get_vector_words(counter):\n",
    "    for key in list(counter.keys()):\n",
    "        if counter[key] < ARBITRATRY_CUTOFF_VALUE:\n",
    "            del counter[key]\n",
    "    return list(counter.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PythonRDD[194] at RDD at PythonRDD.scala:53\n"
     ]
    }
   ],
   "source": [
    "rdd_all = rdd.map(get_relevant_fields)\n",
    "rdd_all = rdd_all.filter(any_missing)\n",
    "rdd_all = rdd_all.map(preprocess_all)\n",
    "#rdd_pos = rdd_all.filter(lambda x: x[1] == 1)\n",
    "#rdd_pos = rdd_pos.reduce(lambda x,y: (x[0]+y[0], x[1], x[2]+y[2]))\n",
    "#rdd_neg = rdd_all.filter(lambda x: x[1] == 0)\n",
    "#rdd_neg = rdd_neg.reduce(lambda x,y: (x[0]+y[0], x[1], x[2]+y[2]))\n",
    "\n",
    "#count = rdd_neg.count()\n",
    "#train_count = count // 4 * 3\n",
    "#test_count = count - train_count\n",
    "\n",
    "#rdd_pos = rdd_pos.sample(False, 0.1)\n",
    "\n",
    "reduced = rdd_all.reduce(lambda x,y: (x[0]+y[0], x[1], x[2]+y[2]))\n",
    "vector_words = get_vector_words(reduced[0])\n",
    "#print(vector_words)\n",
    "n = len(vector_words)\n",
    "\n",
    "def create_vector(row):\n",
    "    vector = []\n",
    "    index = []\n",
    "    length = 0\n",
    "    counter = row[0]\n",
    "    cat = float(row[1])\n",
    "    for i in range(n):\n",
    "        word = vector_words[i]\n",
    "        if word in counter.keys():\n",
    "            vector.append(float(counter[word]))\n",
    "            index.append(i)\n",
    "            length += 1\n",
    "    return LabeledPoint(cat, SparseVector(n, index, vector))\n",
    "\n",
    "rdd_all = rdd_all.map(create_vector)\n",
    "\n",
    "rdd_train, rdd_test = rdd_all.randomSplit(weights=[0.7, 0.3])\n",
    "\n",
    "#print(count)\n",
    "#print(rdd_neg)\n",
    "print(rdd_train)\n",
    "#print(rdd_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Counter([\"a\", \"a\", \"B\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(1.0, (10028,[0,1,2,3,4,5,6,7],[1.0,2.0,1.0,1.0,2.0,2.0,2.0,1.0])),\n",
       " LabeledPoint(1.0, (10028,[1,8,9,10,11,12,13,14,15,16,17,18,19,20],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])),\n",
       " LabeledPoint(1.0, (10028,[1,4,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36],[2.0,2.0,3.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])),\n",
       " LabeledPoint(1.0, (10028,[5,6,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63],[3.0,1.0,1.0,1.0,1.0,2.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])),\n",
       " LabeledPoint(1.0, (10028,[1,64,65,66,67,68,69,70,71,72,73,74],[1.0,1.0,1.0,1.0,1.0,2.0,1.0,1.0,1.0,1.0,1.0,1.0]))]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_train.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVMWithSGD.train(rdd_train, iterations=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import SVMWithSGD\n",
    "from pyspark.mllib.linalg import SparseVector\n",
    "from pyspark.mllib.regression import LabeledPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionAndLabel = rdd_test.map(lambda x: (float(x.label), float(svm.predict(x.features))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics \n",
    "\n",
    "metrics = BinaryClassificationMetrics(predictionAndLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionAndLabel = rdd_test.map(lambda x: (float(x.label), float(0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.mllib.evaluation.BinaryClassificationMetrics at 0x7f7663950d30>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__del__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_java_model',\n",
       " '_sc',\n",
       " 'areaUnderPR',\n",
       " 'areaUnderROC',\n",
       " 'call',\n",
       " 'unpersist']"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.areaUnderPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.0, 1), (1.0, 1), (1.0, 1), (1.0, 1), (1.0, 1)]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictionAndLabel.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
