{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports: pyspark, ml and standard python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "from collections import Counter\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the method that extracts a certain field from a row in the rdd eg. the post body or score. The method uses a regular expression that parses the xml text format strings within the rdd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_field(line, field_name):\n",
    "    found = re.search(\"{}=\\\"(.*?)\\\"\".format(field_name), line)\n",
    "    if found:\n",
    "        return found.group(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the method that extracts all the relevant fields for this analysis and puts them in a list of elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_fields(line):\n",
    "    return [get_field(line, \"Body\"),\n",
    "            get_field(line, \"Score\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the method for the filter that eliminates rows that are missing any of the relevant fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def any_missing(row):\n",
    "    return row[0] and row[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the method that preprocesses the score value. It converts the strings to 1 or 0 integers depending on whether the score is positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_scores(score):\n",
    "    score = int(score)\n",
    "    return 1 if score > 0 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the method that removes stop words from word counters. The stop words were taken from the default english language stop words list from https://www.ranks.nl/stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(counter):\n",
    "    stop_words = set([\"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"arent\", \n",
    "                     \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \n",
    "                     \"cant\", \"cannot\", \"could\", \"couldnt\", \"did\", \"didnt\", \"do\", \"does\", \"doesnt\", \"doing\", \"dont\", \"down\", \n",
    "                     \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"hadnt\", \"has\", \"hasnt\", \"have\", \"havent\", \n",
    "                     \"having\", \"he\", \"hed\", \"hell\", \"hes\", \"her\", \"here\", \"heres\", \"hers\", \"herself\", \"him\", \"himself\", \n",
    "                     \"his\", \"how\", \"hows\", \"i\", \"id\", \"ill\", \"im\", \"ive\", \"if\", \"in\", \"into\", \"is\", \"isnt\", \"it\", \"its\", \n",
    "                     \"its\", \"itself\", \"lets\", \"me\", \"more\", \"most\", \"mustnt\", \"my\", \"myself\", \"no\", \"nor\", \"not\", \"of\", \n",
    "                     \"off\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours \tourselves\", \"out\", \"over\", \"own\", \n",
    "                     \"same\", \"shant\", \"she\", \"shed\", \"shell\", \"shes\", \"should\", \"shouldnt\", \"so\", \"some\", \"such\", \"than\", \n",
    "                     \"that\", \"thats\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"theres\", \"these\", \n",
    "                     \"they\", \"theyd\", \"theyll\", \"theyre\", \"theyve\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \n",
    "                     \"until\", \"up\", \"very\", \"was\", \"wasnt\", \"we\", \"wed\", \"well\", \"were\", \"weve\", \"were\", \"werent\", \"what\", \n",
    "                     \"whats\", \"when\", \"whens\", \"where\", \"wheres\", \"which\", \"while\", \"who\", \"whos\", \"whom\", \"why\", \"whys\", \n",
    "                     \"with\", \"wont\", \"would\", \"wouldnt\", \"you\", \"youd\", \"youll\", \"youre\", \"youve\", \"your\", \"yours\", \n",
    "                     \"yourself\", \"yourselves\"])\n",
    "    words = set(counter.keys())\n",
    "    for word in words:\n",
    "        if word in stop_words:\n",
    "            del counter[word]\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the method for preprocessing text and converting it to a python Counter object that counts the words in the text that will be used for a Bag of Words approach. The method has a number of steps each is described by a comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # remove code snippets\n",
    "    text = re.sub(\"&lt;pre&gt;&lt;code&gt;.*?&lt;/pre&gt;&lt;/code&gt;\", \"\", text)\n",
    "    \n",
    "    # remove html tags\n",
    "    text = re.sub(\"&lt;.*?&gt;\", \"\", text)\n",
    "    \n",
    "    #remove whatever this is\n",
    "    text = re.sub(\"&#xA;\", \"\", text)\n",
    "    \n",
    "    # remove links\n",
    "    text = re.sub(\"https?://.*?\\s|$\", \"\", text)\n",
    "    \n",
    "    # remove symbols\n",
    "    text = re.sub(\"[^a-zA-Z\\s]\", \"\", text)\n",
    "    \n",
    "    # normalize whitespace\n",
    "    text = re.sub(\"\\s+\", \" \", text)\n",
    "    \n",
    "    # lowercase everything\n",
    "    text = text.lower()\n",
    "    \n",
    "    # split text into words\n",
    "    split = text.split()\n",
    "\n",
    "    # count words\n",
    "    counter = Counter(split)\n",
    "    \n",
    "    # remove stop words\n",
    "    counter = remove_stop_words(counter)\n",
    "    \n",
    "    count_tuple_list = []\n",
    "    for key in counter.keys():\n",
    "        count_tuple_list.append((key, counter[key]))\n",
    "    \n",
    "    return count_tuple_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a method that preprocesses all of the elements of the rdd. Converting score strings to 0 or 1 and the text body to word counters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_all(row):\n",
    "    return (preprocess_scores(row[1]), preprocess_text(row[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assert the correctness of the large preprocessing method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert preprocess_text(\"&lt;pre&gt;&lt;code&gt;cprintf('hello world!');&lt;/pre&gt;&lt;/code&gt;\"\n",
    "                       \"https://google.com \"\n",
    "                       \"boulder leave leave it's it it?&lt;pre&gt;&lt;/pre&gt;\") == [(\"boulder\", 1), (\"leave\", 2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a method that converts the counter to a vector of relevant words. The arbitrary cutoff value is the number of repetition of the word that have to occur throughout the data for it to be added to the word vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARBITRATRY_CUTOFF_VALUE = 10\n",
    "\n",
    "\n",
    "def get_vector_words(reduced_count_tuple_list):\n",
    "    vector = []\n",
    "    for item in reduced_count_tuple_list:\n",
    "        if item[1] < ARBITRATRY_CUTOFF_VALUE:\n",
    "            vector.append(item[0])\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the spark context and load the text file to the context, it is an xml file containing post data. Each row of the rdd contains data about one post such as the text body, score and tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(\"local[*]\")\n",
    "rdd = sc.textFile(\"Posts.xml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply all of the filtering and preprocessing methods to the rdd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_all = rdd.map(get_relevant_fields)\n",
    "rdd_all = rdd_all.filter(any_missing)\n",
    "rdd_all = rdd_all.map(preprocess_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset between positive and negative scored posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_pos = rdd_all.filter(lambda x: x[0] == 1)\n",
    "rdd_neg = rdd_all.filter(lambda x: x[0] == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample the positive posts to balance out the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_pos = rdd_pos.sample(False, 0.1, 1)\n",
    "rdd_all = rdd_pos.union(rdd_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduce the rdd in order to get the word count for the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced = rdd_all.flatMap(lambda x: x[1]).reduceByKey(lambda x, y: x + y).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the word vector from the reduced word counts as defined in the get_vector_words method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "VECTOR_WORDS = get_vector_words(reduced)\n",
    "\n",
    "N = len(VECTOR_WORDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a method that converts rdd rows to tuples containing float type category flags of either 1.0 or 0.0 and SparseVectors that rescribe the rows text in the VECTOR_WORDS space. Apply the method to the rdd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector(row):\n",
    "    vector = []\n",
    "    index = []\n",
    "    length = 0\n",
    "    counter = {}\n",
    "    for word, count in row[1]:\n",
    "        counter[word] = count\n",
    "    cat = float(row[0])\n",
    "    for i in range(N):\n",
    "        word = VECTOR_WORDS[i]\n",
    "        if word in counter.keys():\n",
    "            vector.append(float(counter[word]))\n",
    "            index.append(i)\n",
    "            length += 1\n",
    "    return (cat, Vectors.sparse(N, index, vector))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map the rdd data to vectors and then convert it to a spark DataFrame. Having the data in a DataFrame will enable the use of the state of the art dataframe based machine learning library that comes with spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_points = rdd_all.map(create_vector)\n",
    "\n",
    "sql = SQLContext(sc)\n",
    "\n",
    "df_points = sql.createDataFrame(rdd_points, [\"label\", \"features\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataframe into a training and test set for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = df_points.randomSplit(weights=[0.7, 0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a support vector machine on the training data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsvc = LinearSVC(maxIter = 10, regParam = 0.1)\n",
    "lsvcModel = lsvc.fit(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the support vector model to predict values from the test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lsvcModel.transform(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate binary classification metrics to evaulate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6404455099390671"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "\n",
    "evaluation.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default metric returned by the evaluate method is the area under the ROC curve."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
