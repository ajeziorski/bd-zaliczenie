{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports: pyspark, mllib and standard python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "\n",
    "from pyspark.mllib.classification import SVMWithSGD\n",
    "from pyspark.mllib.linalg import SparseVector\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics \n",
    "\n",
    "from collections import Counter\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the method that extracts a certain field from a row in the rdd eg. the post body or score. The method uses a regular expression that parses the xml text format strings within the rdd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_field(line, field_name):\n",
    "    found = re.search(\"{}=\\\"(.*?)\\\"\".format(field_name), line)\n",
    "    if found:\n",
    "        return found.group(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the method that extracts all the relevant fields for this analysis and puts them in a list of elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_fields(line):\n",
    "    return [get_field(line, \"Body\"),\n",
    "            get_field(line, \"Score\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the method for the filter that eliminates rows that are missing any of the relevant fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def any_missing(row):\n",
    "    return row[0] and row[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the method that preprocesses the score value. It converts the strings to 1 or 0 integers depending on whether the score is positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_scores(score):\n",
    "    score = int(score)\n",
    "    return 1 if score > 0 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the method that removes stop words from word counters. The stop words were taken from the default english language stop words list from https://www.ranks.nl/stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(counter):\n",
    "    stop_words = set([\"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"arent\", \n",
    "                     \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \n",
    "                     \"cant\", \"cannot\", \"could\", \"couldnt\", \"did\", \"didnt\", \"do\", \"does\", \"doesnt\", \"doing\", \"dont\", \"down\", \n",
    "                     \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"hadnt\", \"has\", \"hasnt\", \"have\", \"havent\", \n",
    "                     \"having\", \"he\", \"hed\", \"hell\", \"hes\", \"her\", \"here\", \"heres\", \"hers\", \"herself\", \"him\", \"himself\", \n",
    "                     \"his\", \"how\", \"hows\", \"i\", \"id\", \"ill\", \"im\", \"ive\", \"if\", \"in\", \"into\", \"is\", \"isnt\", \"it\", \"its\", \n",
    "                     \"its\", \"itself\", \"lets\", \"me\", \"more\", \"most\", \"mustnt\", \"my\", \"myself\", \"no\", \"nor\", \"not\", \"of\", \n",
    "                     \"off\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours \tourselves\", \"out\", \"over\", \"own\", \n",
    "                     \"same\", \"shant\", \"she\", \"shed\", \"shell\", \"shes\", \"should\", \"shouldnt\", \"so\", \"some\", \"such\", \"than\", \n",
    "                     \"that\", \"thats\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"theres\", \"these\", \n",
    "                     \"they\", \"theyd\", \"theyll\", \"theyre\", \"theyve\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \n",
    "                     \"until\", \"up\", \"very\", \"was\", \"wasnt\", \"we\", \"wed\", \"well\", \"were\", \"weve\", \"were\", \"werent\", \"what\", \n",
    "                     \"whats\", \"when\", \"whens\", \"where\", \"wheres\", \"which\", \"while\", \"who\", \"whos\", \"whom\", \"why\", \"whys\", \n",
    "                     \"with\", \"wont\", \"would\", \"wouldnt\", \"you\", \"youd\", \"youll\", \"youre\", \"youve\", \"your\", \"yours\", \n",
    "                     \"yourself\", \"yourselves\"])\n",
    "    words = set(counter.keys())\n",
    "    for word in words:\n",
    "        if word in stop_words:\n",
    "            del counter[word]\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the method for preprocessing text and covnerting it to a python Counter object that counts the words in the text that will be used for a Bag of Words approach. The method has a number of steps each is described by a comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # remove code snippets\n",
    "    text = re.sub(\"&lt;pre&gt;&lt;code&gt;.*?&lt;/pre&gt;&lt;/code&gt;\", \"\", text)\n",
    "    \n",
    "    # remove html tags\n",
    "    text = re.sub(\"&lt;.*?&gt;\", \"\", text)\n",
    "    \n",
    "    #remove whatever this is\n",
    "    text = re.sub(\"&#xA;\", \"\", text)\n",
    "    \n",
    "    # remove links\n",
    "    text = re.sub(\"https?://.*?\\s|$\", \"\", text)\n",
    "    \n",
    "    # remove symbols\n",
    "    text = re.sub(\"[^a-zA-Z\\s]\", \"\", text)\n",
    "    \n",
    "    # normalize whitespace\n",
    "    text = re.sub(\"\\s+\", \" \", text)\n",
    "    \n",
    "    # lowercase everything\n",
    "    text = text.lower()\n",
    "    \n",
    "    # split text into words\n",
    "    split = text.split()\n",
    "\n",
    "    # count words\n",
    "    counter = Counter(split)\n",
    "    \n",
    "    # remove stop words\n",
    "    counter = remove_stop_words(counter)\n",
    "    \n",
    "    return counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a method that preprocesses all of the elements of the rdd. Converting score strings to 0 or 1 and the text body to word counters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_all(row):\n",
    "    return (preprocess_text(row[0]), preprocess_scores(row[1]), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assert the correctness of the large preprocessing method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert preprocess_text(\"&lt;pre&gt;&lt;code&gt;cprintf('hello world!');&lt;/pre&gt;&lt;/code&gt;\"\n",
    "                       \"https://google.com \"\n",
    "                       \"boulder leave it's it it?&lt;pre&gt;&lt;/pre&gt;\") == Counter([\"leave\", \"boulder\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a method that converts the counter to a vector of relevant words. The arbitrary cutoff value is the number of repetition of the word that have to occur throughout the data for it to be added to the word vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARBITRATRY_CUTOFF_VALUE = 10\n",
    "\n",
    "\n",
    "def get_vector_words(counter):\n",
    "    for key in list(counter.keys()):\n",
    "        if counter[key] < ARBITRATRY_CUTOFF_VALUE:\n",
    "            del counter[key]\n",
    "    return list(counter.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the spark context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(\"local[*]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the text file to the context, it is an xml file containing post data. Each row of the rdd contains data about one post such as the text body, score and tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.textFile(\"Posts.xml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply all of the filtering and preprocessing methods to the rdd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_all = rdd.map(get_relevant_fields)\n",
    "rdd_all = rdd_all.filter(any_missing)\n",
    "rdd_all = rdd_all.map(preprocess_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset between positive and negative scored posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_pos = rdd_all.filter(lambda x: x[1] == 1)\n",
    "rdd_neg = rdd_all.filter(lambda x: x[1] == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample the positive posts to balance out the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_pos = rdd_pos.sample(False, 0.1, 1)\n",
    "rdd_all = rdd_pos.union(rdd_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduce the rdd in order to get the word count for the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced = rdd_all.reduce(lambda x,y: (x[0] + y[0], x[1], x[2] + y[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the word vector from the reduced word counts as defined in the get_vector_words method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "VECTOR_WORDS = get_vector_words(reduced[0])\n",
    "\n",
    "N = len(VECTOR_WORDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a method that converts rdd rows to LabelPoint objects containing float type category flags of either 1.0 or 0.0 and SparseVectors that rescribe the rows text in the VECTOR_WORDS space. Apply the method to the rdd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector(row):\n",
    "    vector = []\n",
    "    index = []\n",
    "    length = 0\n",
    "    counter = row[0]\n",
    "    cat = float(row[1])\n",
    "    for i in range(N):\n",
    "        word = VECTOR_WORDS[i]\n",
    "        if word in counter.keys():\n",
    "            vector.append(float(counter[word]))\n",
    "            index.append(i)\n",
    "            length += 1\n",
    "    return LabeledPoint(cat, SparseVector(N, index, vector))\n",
    "\n",
    "rdd_all = rdd_all.map(create_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the rdd into a training and test set for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_train, rdd_test = rdd_all.randomSplit(weights=[0.7, 0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a support vector machine on the training data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVMWithSGD.train(rdd_train, iterations=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the support vector model to predict values from the test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionAndLabel = rdd_test.map(lambda x: (float(x.label), float(svm.predict(x.features))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate binary classification metrics to evaulate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model area under ROC:\n",
      "0.5267286018885167\n"
     ]
    }
   ],
   "source": [
    "metrics = BinaryClassificationMetrics(predictionAndLabel)\n",
    "\n",
    "print(\"Model area under ROC:\")\n",
    "print(metrics.areaUnderROC)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
